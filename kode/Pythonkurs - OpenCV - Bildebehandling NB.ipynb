{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cb2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # pip install opencv-python-headless or conda install opencv \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f350700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgr_image = cv2.imread(\"../data/image_video/topaz.jpg\") # cv2 read in BGR format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70758913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to jupyters architecture we can not use cv2.imshow() so we create a helper method to utilize pyplot.\n",
    "def show_image(image, title):\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f88bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the RGB image.\n",
    "show_image(cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB), \"All the nice colors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e9b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to grayscale for more efficient work.\n",
    "# Do operations on grayscale are more efficient since there is less colors.\n",
    "gray_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY) # First: Make it grayscale.\n",
    "show_image(cv2.cvtColor(gray_image, cv2.COLOR_BGR2RGB), \"Greyscale\") # Third: View the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bfa1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blur the image with Gaussian blur, a popular and relatively fast blur algorithm.\n",
    "# We use a window of size 7px * 7px, which means that we average values in the window for blur effect.\n",
    "# Larger window will result in more blur, but will be slower.\n",
    "blurred_image = cv2.GaussianBlur(bgr_image, (7,7), 0)\n",
    "show_image(cv2.cvtColor(blurred_image, cv2.COLOR_BGR2RGB), \"Blurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b3b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All together now.\n",
    "show_image(cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB), \"All the nice colors...\")\n",
    "show_image(cv2.cvtColor(gray_image, cv2.COLOR_BGR2RGB), \"Greyscale...\")\n",
    "show_image(cv2.cvtColor(blurred_image, cv2.COLOR_BGR2RGB), \"Blurred...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fcd369",
   "metadata": {},
   "source": [
    "# Edge detection med OpenCV\n",
    "\n",
    "Nyttig når vi skal finne objekter i et bilde. Algoritmen ser etter endringer i farge, lysstyrke med mer for å finne kanter.\n",
    "\n",
    "[http://en.wikipedia.org/wiki/Edge_detection](http://en.wikipedia.org/wiki/Edge_detection)\n",
    "\n",
    "[http://en.wikipedia.org/wiki/Canny_edge_detector](http://en.wikipedia.org/wiki/Canny_edge_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea4c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.opencv.org/4.6.0/dd/d1a/group__imgproc__feature.html#ga04723e007ed888ddf11d9ba04e2232de\n",
    "canny = cv2.Canny(blurred_image, 10, 50) # cv2.Canny(image, lower treshold, upper treshold)\n",
    "show_image(cv2.cvtColor(canny, cv2.COLOR_BGR2RGB), \"Canny edge detection...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80976771",
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv2.Canny(blurred_image, 50, 150) # cv2.Canny(image, lower treshold, upper treshold)\n",
    "show_image(cv2.cvtColor(canny, cv2.COLOR_BGR2RGB), \"Canny edge detection with higher tresholds...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09ae7b8",
   "metadata": {},
   "source": [
    "# Finne objekter med OpenCV\n",
    "\n",
    "Nå som vi har greid å detektere kanter på objekter kan vi utvide koden vår til å telle objekter i bildet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab13cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a new image for processing.\n",
    "bgr_image_contours = cv2.imread(\"../data/image_video/cards.jpg\") # cv2 read in BGR format.\n",
    "gray_image_contours = cv2.cvtColor(bgr_image_contours, cv2.COLOR_BGR2GRAY) # Grayscale for efficient processing\n",
    "blurred_image_contours = cv2.GaussianBlur(gray_image_contours, (7,7), 0) # Blur it for efficient processing\n",
    "canny_contours = cv2.Canny(blurred_image_contours, 30, 100) # Detect the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7cdbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contours are just a fancy name for edges.\n",
    "# RETR_EXTERNAL = Find only the outmost contours, not contours inside contours.\n",
    "# CHAIN_APPROX_SIMPLE = Use simple approximation.\n",
    "# https://docs.opencv.org/4.6.0/d3/dc0/group__imgproc__shape.html#gadf1ad6a0b82947fa1fe3c3d497f260e0\n",
    "contours, hierarchy = cv2.findContours(canny_contours, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5063fce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(cv2.cvtColor(bgr_image_contours, cv2.COLOR_BGR2RGB), \"A collection of objects\")\n",
    "show_image(cv2.cvtColor(canny_contours, cv2.COLOR_BGR2RGB), \"Number of objects found = %s\" % len(contours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051a1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bgr_image_contours = The image we want to draw on..\n",
    "# contours = The contours we found in the last findContours(...) function. \n",
    "# -1 = We want all contours to be drawn (we can choose to only draw certain contours). \n",
    "# (0,255,0) = Color of the contour we are drawing.\n",
    "# 2 = Thickness.\n",
    "# https://docs.opencv.org/3.4/d6/d6e/group__imgproc__draw.html#ga746c0625f1781f1ffc9056259103edbc\n",
    "traced_contours = cv2.drawContours(bgr_image_contours, contours, -1, (0,255,0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5ee4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(cv2.cvtColor(traced_contours, cv2.COLOR_BGR2RGB), \"Number of objects found = %s\" % len(contours))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e409170f",
   "metadata": {},
   "source": [
    "# Ansiktsgjenkjenkjenning med OpenCV\n",
    "\n",
    "Haar Cascade er en ML objektgjenkjennings algoritme som er basert på en artikkel som ble publisert i \"International Journal of Computer Vision\" i 2001. Artikkelen var igjen basert på forskningsoppgaven deres \"Rapid Object Detection using a Boosted Cascade of Simple Features\".\n",
    "\n",
    "Konseptet baserer seg på at man kan trene opp / finne mønstre som kan gjenbrukes senere. Man har et (eller mange bilder) av ansikt hvor bildene scannes etter mønstre som går igjen i alle bildene som er ansikt. Et mønster kan være hvordan forskjellige piksler står i forhold til hverandre, pikslenes skarphet og lysintensitet med mer. Disse kjennetegnene lagres som såkalte features, og for et ansikt kan vi ha rundt 6000 slike features. Ved hjelp av disse featurene kan vi da teste andre bilder, og om vi får treff på nok features så har vi funnet objektet vi leter etter.\n",
    "\n",
    "Original paper: [https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf](https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf)\n",
    "\n",
    "Flere datasett: [https://github.com/opencv/opencv/tree/master/data/haarcascades](https://github.com/opencv/opencv/tree/master/data/haarcascades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e2d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the haar cascade\n",
    "cascPath = \"../data/image_video/haarcascade_frontalface_default.xml\" # Just an xml file that contains data about a face.\n",
    "faceCascade = cv2.CascadeClassifier(cascPath) # Load the cascade into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd37bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_image = cv2.imread(\"../data/image_video/abba.png\") # cv2 read in BGR format.\n",
    "gray_image_face = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03daa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The detectMultiScale function is a general function that detects objects.\n",
    "# Since we are calling it on the face cascade, thats what it detects. \n",
    "# gray_image_face = Our image, in grayscale.\n",
    "# scaleFactor = Compensate for faces being near / far from the camera effect. \n",
    "# minNeighbors = How many objects are detected near the current moving window before it declares the face found. \n",
    "# minSize = The size of each window.\n",
    "faces = faceCascade.detectMultiScale(\n",
    "    gray_image_face,\n",
    "    scaleFactor=1.1,\n",
    "    minNeighbors=5,\n",
    "    minSize=(30, 30),\n",
    "    flags = cv2.CASCADE_SCALE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c61c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate the list of faces and draw a rectangle around the faces.\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(face_image, (x, y), (x+w, y+h), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bd561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB), \"Number of faces found = %s\" % len(faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e775005",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_image_b = cv2.imread(\"../data/image_video/celebrities.png\") # cv2 read in BGR format.\n",
    "gray_image_face_b = cv2.cvtColor(face_image_b, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53897425",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = faceCascade.detectMultiScale(\n",
    "    gray_image_face_b,\n",
    "    scaleFactor=1.1,\n",
    "    minNeighbors=1,\n",
    "    minSize=(30, 30),\n",
    "    flags = cv2.CASCADE_SCALE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e19459",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Draw a rectangle around the faces\n",
    "print(faces)\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(face_image_b, (x, y), (x+w, y+h), (0, 255, 0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c434810",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(cv2.cvtColor(face_image_b, cv2.COLOR_BGR2RGB), \"Number of faces found = %s\" % len(faces))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ff9a4",
   "metadata": {},
   "source": [
    "Vi har nå jobbet med stillbilder, men det skal ikke mange ekstra linjer med kode til for å analysere videoer (som er en samling av stillbilder) på samme måten. Som nevnt er sanntidsbehandling hovedfokuset til OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce04596-5eeb-4444-9583-c310307ad341",
   "metadata": {},
   "source": [
    "## Oppgave\n",
    "\n",
    "0: Opprett et nytt kodeprosjekt / fil.\n",
    "\n",
    "1: Finn et egnet bilde og se om du greier å detektere andre features, f.eks munn / øyner.\n",
    "\n",
    "NB! Dere finner flere trente haarcascade set her [https://github.com/opencv/opencv/tree/master/data/haarcascades](https://github.com/opencv/opencv/tree/master/data/haarcascades)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
